{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e71d344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (4.21.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from selenium) (0.25.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from selenium) (4.12.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\bhawn\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d738f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef49bf99",
   "metadata": {},
   "source": [
    "Q1: In this question you have to scrape data using the filters available on the webpage You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ecc1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the naukri page on automated chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f048335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation as required \n",
    "designation = driver.find_element(By.CLASS_NAME, \"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96771405",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea732ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting delhi/ncr region as location\n",
    "delhincr_search= driver.find_element(By.XPATH, \"/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[5]/div[2]/div[3]/label/p/span[1]\")\n",
    "delhincr_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88b420a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting desired salary as mentioned in question\n",
    "salary_search=driver.find_element(By.XPATH,'/html/body/div/div/main/div[1]/div[1]/div/div/div[2]/div[6]/div[2]/div[2]/label/p/span[1]')\n",
    "salary_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afc8cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62900ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/a')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ni-job-tuple-icon ni-job-tuple-icon-srp-location loc\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping company name from the given page    \n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\" comp-name mw-25\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)   \n",
    "\n",
    "\n",
    "# scraping job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfcbc414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d9a5bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Essenware</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Orange Business Services</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - NLP, Gen AI</td>\n",
       "      <td>Noida, Mumbai, Hyderabad/Secunderabad, Gurgaon...</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python Data Scientist</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Wizaltia Hr Solutions</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...</td>\n",
       "      <td>Newwave Technologies</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Digital Glyde</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>PayU</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Orange Business Services</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          TITLE  \\\n",
       "0                Data Scientist   \n",
       "1                Data Scientist   \n",
       "2      Associate Data Scientist   \n",
       "3  Data Scientist - NLP, Gen AI   \n",
       "4         Python Data Scientist   \n",
       "5                Data Scientist   \n",
       "6                Data Scientist   \n",
       "7                Data Scientist   \n",
       "8           Lead Data Scientist   \n",
       "9                Data Scientist   \n",
       "\n",
       "                                            LOCATION  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "1        Pune, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "2                                              Noida   \n",
       "3  Noida, Mumbai, Hyderabad/Secunderabad, Gurgaon...   \n",
       "4                                           Gurugram   \n",
       "5                                              Noida   \n",
       "6  Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...   \n",
       "7  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "8  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "9  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...   \n",
       "\n",
       "               COMPANY_NAME EXPERIENCE  \n",
       "0                 Essenware    2-5 Yrs  \n",
       "1                  Ericsson    3-7 Yrs  \n",
       "2  Orange Business Services    1-5 Yrs  \n",
       "3   R Systems International    5-8 Yrs  \n",
       "4     Wizaltia Hr Solutions    2-7 Yrs  \n",
       "5        Scienaptic Systems    2-7 Yrs  \n",
       "6      Newwave Technologies    1-3 Yrs  \n",
       "7             Digital Glyde    3-7 Yrs  \n",
       "8                      PayU    3-7 Yrs  \n",
       "9  Orange Business Services    3-7 Yrs  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'TITLE':job_title,\"LOCATION\":job_location,'COMPANY_NAME':company_name,\"EXPERIENCE\":experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1dd0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d660b0d",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3727eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the shine page on automated chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(' https://www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee637341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering data analyst designation\n",
    "designation = driver.find_element(By.ID, \"id_q\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ac2ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering bangalore as loaction\n",
    "location = driver.find_element(By.ID, \"id_loc\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9951218",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72baa8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74790367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//strong[@class=\"jobCard_pReplaceH2__xWmHg\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping job location from the given page   \n",
    "location_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping job title from the given page   \n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)  \n",
    "    \n",
    "# scraping job title from the given page \n",
    "experience_tags=driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4654c074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9589046e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst , Senior Data Analyst , Data Anal...</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "      <td>appsoft solutions</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>5 to 9 Yrs</td>\n",
       "      <td>mackenzie modern it solutions priva...</td>\n",
       "      <td>5 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "      <td>vision india services private limit...</td>\n",
       "      <td>2 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>9 to 14 Yrs</td>\n",
       "      <td>neo impex stainless private limited</td>\n",
       "      <td>9 to 14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>5 to 9 Yrs</td>\n",
       "      <td>mackenzie modern it solutions priva...</td>\n",
       "      <td>5 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>4 to 5 Yrs</td>\n",
       "      <td>valenta bpo solutions pvt. ltd.</td>\n",
       "      <td>4 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst (Need Immediate Joiner)</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "      <td>r.s textile</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst (Need Immediate Joiner)</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "      <td>r.s textile</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE     LOCATION  \\\n",
       "0  Data Analyst , Senior Data Analyst , Data Anal...   0 to 4 Yrs   \n",
       "1                                  Lead Data Analyst   5 to 9 Yrs   \n",
       "2                                       Data Analyst   2 to 4 Yrs   \n",
       "3                              Clinical Data Analyst    0 to 1 Yr   \n",
       "4                              Clinical Data Analyst    0 to 1 Yr   \n",
       "5                                       Data Analyst  9 to 14 Yrs   \n",
       "6                                  Lead Data Analyst   5 to 9 Yrs   \n",
       "7                                       Data Analyst   4 to 5 Yrs   \n",
       "8               Data Analyst (Need Immediate Joiner)   0 to 4 Yrs   \n",
       "9               Data Analyst (Need Immediate Joiner)   0 to 4 Yrs   \n",
       "\n",
       "                             COMPANY_NAME   EXPERIENCE  \n",
       "0                       appsoft solutions   0 to 4 Yrs  \n",
       "1  mackenzie modern it solutions priva...   5 to 9 Yrs  \n",
       "2  vision india services private limit...   2 to 4 Yrs  \n",
       "3                           techno endura    0 to 1 Yr  \n",
       "4                           techno endura    0 to 1 Yr  \n",
       "5     neo impex stainless private limited  9 to 14 Yrs  \n",
       "6  mackenzie modern it solutions priva...   5 to 9 Yrs  \n",
       "7         valenta bpo solutions pvt. ltd.   4 to 5 Yrs  \n",
       "8                             r.s textile   0 to 4 Yrs  \n",
       "9                             r.s textile   0 to 4 Yrs  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'TITLE':job_title,\"LOCATION\":job_location,'COMPANY_NAME':company_name,\"EXPERIENCE\":experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc513ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46bbf618",
   "metadata": {},
   "source": [
    "Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\n",
    "Asshown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55ee6c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the flipkart page link as mentioned on automated chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('  https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a6aa19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making an empty list\n",
    "ratings=[]\n",
    "summary=[]\n",
    "review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6be1aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping ratings from the given page\n",
    "rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"XQDdHH Ga3i8K\"]')\n",
    "for i in rating_tags:\n",
    "    rat=i.text\n",
    "    ratings.append(rat)\n",
    "    \n",
    "\n",
    "# scraping summary from the given page    \n",
    "summary_tags=driver.find_elements(By.XPATH,'//p[@class=\"z9E0IG\"]')\n",
    "for i in summary_tags:\n",
    "    summ =i.text\n",
    "    summary.append(summ)\n",
    "    \n",
    "    \n",
    "#scraping review of product from given page\n",
    "review_tags=driver.find_elements(By.XPATH,'//div[@class=\"ZmyHeo\"]')\n",
    "for i in review_tags:\n",
    "    rev=i.text\n",
    "    review.append(rev)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ad2980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(ratings),len(summary),len(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04659617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RATINGS</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>REVIEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money 😍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Perfect Product!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>It’s really awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Photos super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Super🔥 and good performance 👌❤️</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RATINGS              SUMMARY  \\\n",
       "0       5  Best in the market!   \n",
       "1       5       Classy product   \n",
       "2       5    Terrific purchase   \n",
       "3       5    Worth every penny   \n",
       "4       5            Just wow!   \n",
       "5       5            Wonderful   \n",
       "6       5             Terrific   \n",
       "7       5            Must buy!   \n",
       "8       5     Perfect product!   \n",
       "9       5            Fabulous!   \n",
       "\n",
       "                                              REVIEW  \n",
       "0                                        Good Camera  \n",
       "1  Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "2                                  Value for money 😍  \n",
       "3  Feeling awesome after getting the delivery of ...  \n",
       "4                                  Perfect Product!!  \n",
       "5                             This is amazing at all  \n",
       "6                                     Very very good  \n",
       "7                                It’s really awesome  \n",
       "8                                       Photos super  \n",
       "9                    Super🔥 and good performance 👌❤️  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"RATINGS\":ratings,\"SUMMARY\":summary,'REVIEW':review})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55e12179",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingss=[]\n",
    "summarys=[]\n",
    "reviews=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapting data from the next pages\n",
    "start=0\n",
    "end=20\n",
    "for page in range(start,end):\n",
    "    ratss=driver.find_elements(By.XPATH,'//div[@class=\"XQDdHH Ga3i8K\"]')\n",
    "    for i in ratss:\n",
    "        ratingss.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]')\n",
    "    next_button.click()\n",
    "    time.sleep(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapting data from the next pages\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    summs=driver.find_elements(By.XPATH,'//p[@class=\"z9E0IG\"]')\n",
    "    for i in summs:\n",
    "        summarys.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapting data from the next pages\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    revs=driver.find_elements(By.XPATH,'//div[@class=\"ZmyHeo\"]')\n",
    "    for i in revs:\n",
    "        reviews.append(i.text)\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "next_button.click()\n",
    "time.sleep(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62db0c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(ratingss),len(summarys),len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "baa79caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RATINGS</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>REVIEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Photos super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money 😍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Perfect Product!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>It’s really awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Super🔥 and good performance 👌❤️</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RATINGS              SUMMARY  \\\n",
       "0        5     Perfect product!   \n",
       "1        5  Best in the market!   \n",
       "2        5       Classy product   \n",
       "3        5    Terrific purchase   \n",
       "4        5    Worth every penny   \n",
       "..     ...                  ...   \n",
       "95       5            Just wow!   \n",
       "96       5             Terrific   \n",
       "97       5            Wonderful   \n",
       "98       5            Must buy!   \n",
       "99       5            Fabulous!   \n",
       "\n",
       "                                               REVIEW  \n",
       "0                                        Photos super  \n",
       "1                                         Good Camera  \n",
       "2   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "3                                   Value for money 😍  \n",
       "4   Feeling awesome after getting the delivery of ...  \n",
       "..                                                ...  \n",
       "95                                  Perfect Product!!  \n",
       "96                                     Very very good  \n",
       "97                             This is amazing at all  \n",
       "98                                It’s really awesome  \n",
       "99                    Super🔥 and good performance 👌❤️  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a dataframe of top 100 products\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({\"RATINGS\":ratingss,\"SUMMARY\":summarys,'REVIEW':reviews})\n",
    "df[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de30c6c",
   "metadata": {},
   "source": [
    "Q4: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "af2654e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the flipkart page link as mentioned on automated chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(' https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "76a63308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering sneakers in searchn\n",
    "designation = driver.find_element(By.CLASS_NAME, \"Pke_EE\")\n",
    "designation.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c3e826c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button\n",
    "search=driver.find_element(By.CLASS_NAME, \"_2iLD__\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ba33d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_desr=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "90d2a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping brand name of product from given page\n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"syl9yP\"]')\n",
    "for i in brand_tags:\n",
    "    rat=i.text\n",
    "    brand.append(rat)\n",
    "\n",
    "#scraping description of product from given page    \n",
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"WKTcLC\"]')\n",
    "for i in product_tags:\n",
    "    summ =i.text\n",
    "    product_desr.append(summ)\n",
    "    \n",
    "    \n",
    "#scraping price of product from given page    \n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"Nx9bqj\"]')\n",
    "for i in price_tags:\n",
    "    rev=i.text\n",
    "    price.append(rev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6358508b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 35 40\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(product_desr),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f2695d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ego by NS</td>\n",
       "      <td>₹298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>asian</td>\n",
       "      <td>₹749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abros</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>corsac</td>\n",
       "      <td>₹430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Aeonik</td>\n",
       "      <td>₹451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ATOM</td>\n",
       "      <td>₹1,685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Krors</td>\n",
       "      <td>₹479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aadi</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>asian</td>\n",
       "      <td>₹749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>₹1,569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BERSACHE</td>\n",
       "      <td>₹1,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>₹550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AMICO</td>\n",
       "      <td>₹485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>U.S. POLO ASSN.</td>\n",
       "      <td>₹1,037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ATOM</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>U.S. POLO ASSN.</td>\n",
       "      <td>₹1,177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BRAND   PRICE\n",
       "0         Ego by NS    ₹298\n",
       "1            BRUTON    ₹608\n",
       "2          Red Tape  ₹1,119\n",
       "3          URBANBOX    ₹299\n",
       "4          Red Tape  ₹1,179\n",
       "5             asian    ₹749\n",
       "6            BRUTON    ₹512\n",
       "7             Abros    ₹799\n",
       "8          Red Tape  ₹1,259\n",
       "9          Red Tape  ₹1,059\n",
       "10           corsac    ₹430\n",
       "11           BRUTON    ₹608\n",
       "12           Aeonik    ₹451\n",
       "13             ATOM  ₹1,685\n",
       "14         Red Tape  ₹1,059\n",
       "15            Krors    ₹479\n",
       "16           BRUTON    ₹388\n",
       "17             aadi    ₹299\n",
       "18            asian    ₹749\n",
       "19         Red Tape  ₹1,769\n",
       "20           BRUTON    ₹499\n",
       "21           BRUTON    ₹551\n",
       "22         URBANBOX    ₹299\n",
       "23        Deals4you    ₹399\n",
       "24         Red Tape  ₹1,179\n",
       "25         Red Tape  ₹1,379\n",
       "26             PUMA  ₹1,569\n",
       "27           BRUTON    ₹608\n",
       "28         BERSACHE  ₹1,599\n",
       "29         Red Tape  ₹1,129\n",
       "30         RapidBox    ₹550\n",
       "31            AMICO    ₹485\n",
       "32  U.S. POLO ASSN.  ₹1,037\n",
       "33             ATOM    ₹999\n",
       "34         Roadster    ₹949\n",
       "35         Red Tape  ₹1,649\n",
       "36           BRUTON    ₹608\n",
       "37           BRUTON    ₹569\n",
       "38         Red Tape  ₹1,039\n",
       "39  U.S. POLO ASSN.  ₹1,177"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'BRAND':brand,'PRICE':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "62c8fce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=[]\n",
    "product_desrs=[]\n",
    "prices=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5379bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapting data from the next pages\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    rats=driver.find_elements(By.XPATH,'//div[@class=\"syl9yP\"]')\n",
    "    for i in rats:\n",
    "        brands.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_9QVEpD\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "21d50a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapting data from the next pages\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    summs=driver.find_elements(By.XPATH,'//a[@class=\"WKTcLC\"]')\n",
    "    for i in summs:\n",
    "         product_desrs.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_9QVEpD\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fff0216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapting data from the next pages\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    revs=driver.find_elements(By.XPATH,'//div[@class=\"Nx9bqj\"]')\n",
    "    for i in revs:\n",
    "        prices.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_9QVEpD\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "576b26ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 96 120\n"
     ]
    }
   ],
   "source": [
    "print(len(brands),len(product_desrs),len(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a5d98003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ego by NS</td>\n",
       "      <td>₹298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>₹1,179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Krors</td>\n",
       "      <td>₹479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>aadi</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BERSACHE</td>\n",
       "      <td>₹1,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BRAND   PRICE\n",
       "0   Ego by NS    ₹298\n",
       "1      BRUTON    ₹608\n",
       "2    Red Tape  ₹1,119\n",
       "3    URBANBOX    ₹299\n",
       "4    Red Tape  ₹1,179\n",
       "..        ...     ...\n",
       "95      Krors    ₹479\n",
       "96     BRUTON    ₹388\n",
       "97       aadi    ₹299\n",
       "98   BERSACHE  ₹1,599\n",
       "99  Deals4you    ₹399\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'BRAND':brands,'PRICE':prices})\n",
    "df[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f310f79",
   "metadata": {},
   "source": [
    "Q5: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "92571f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening amazon page on automated chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('  https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f32c74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering laptop as search element\n",
    "designation = driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "designation.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ec2b1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.ID, \"nav-search-submit-button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a227406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection inteli7 as cpu processor\n",
    "cpu_search=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[20]/span/span[11]/li/span/a/span')\n",
    "cpu_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7d6aaf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "ratings=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "204cd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping brand name  of product from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "for i in title_tags:\n",
    "    rat=i.text\n",
    "    title.append(rat)\n",
    "\n",
    "    \n",
    "#scraping ratings of product from given page    \n",
    "product_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-icon-alt\"]')\n",
    "for i in product_tags:\n",
    "    summ =i.text\n",
    "    ratings.append(summ)\n",
    "    \n",
    "#scraping price of product from given page    \n",
    "price_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags:\n",
    "    rev=i.text\n",
    "    price.append(rev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "89feffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24 24\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(ratings),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1ba41bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>RATINGS</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Aspire Lite 12th Gen Intel Core i7-1255U ...</td>\n",
       "      <td></td>\n",
       "      <td>61,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...</td>\n",
       "      <td></td>\n",
       "      <td>49,780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td></td>\n",
       "      <td>52,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>49,780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS [Smartchoice] Vivobook 15, Intel Core i7-...</td>\n",
       "      <td></td>\n",
       "      <td>78,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...</td>\n",
       "      <td></td>\n",
       "      <td>62,933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dell Inspiron 7420 2in1 Laptop, Intel Core i7-...</td>\n",
       "      <td></td>\n",
       "      <td>61,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Samsung Galaxy Book3 Core i7 13th Gen 1355U - ...</td>\n",
       "      <td></td>\n",
       "      <td>64,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Travelmate Business Laptop Intel Core i7-...</td>\n",
       "      <td></td>\n",
       "      <td>77,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell Inspiron 3530 Laptop, 13th Generation Int...</td>\n",
       "      <td></td>\n",
       "      <td>70,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE RATINGS   PRICE\n",
       "0  Acer Aspire Lite 12th Gen Intel Core i7-1255U ...          61,990\n",
       "1  MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...          49,780\n",
       "2  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...          52,999\n",
       "3  Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 1...          49,780\n",
       "4  ASUS [Smartchoice] Vivobook 15, Intel Core i7-...          78,990\n",
       "5  HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...          62,933\n",
       "6  Dell Inspiron 7420 2in1 Laptop, Intel Core i7-...          61,990\n",
       "7  Samsung Galaxy Book3 Core i7 13th Gen 1355U - ...          64,490\n",
       "8  Acer Travelmate Business Laptop Intel Core i7-...          77,490\n",
       "9  Dell Inspiron 3530 Laptop, 13th Generation Int...          70,999"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'TITLE':title,'RATINGS':ratings,'PRICE':price})\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b017760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6ae4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad48dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f990d81e",
   "metadata": {},
   "source": [
    "Q6: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on Top Quote\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d2b95657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening azquotes page on automated chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(' https://www.azquotes.com/ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8e2fdc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on top quotes to get result\n",
    "topquote_search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a\" )\n",
    "topquote_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "30a38297",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote=[]\n",
    "author=[]\n",
    "type_quote=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0a212b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping quotes from given page\n",
    "quote_tags=driver.find_elements(By.CLASS_NAME,'wrap-block')\n",
    "for i in quote_tags:\n",
    "    rat=i.text\n",
    "    quote.append(rat)\n",
    "\n",
    "#scraping authors of quotes from given page    \n",
    "author_tags=driver.find_elements(By.CLASS_NAME,'author')\n",
    "for i in author_tags:\n",
    "    summ =i.text\n",
    "    author.append(summ)\n",
    "\n",
    "#scraping type of quotes from given page    \n",
    "type_quote_tags=driver.find_elements(By.CLASS_NAME,'tags')\n",
    "for i in type_quote_tags:\n",
    "    rev=i.text\n",
    "    type_quote.append(rev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "11eb3901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(quote),len(author),len(type_quote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cad2007c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUOTE</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>TYPE OF QUOTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>When the going gets weird, the weird turn pro....</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Music, Sports, Hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>When a train goes through a tunnel and it gets...</td>\n",
       "      <td>Corrie Ten Boom</td>\n",
       "      <td>Trust, Encouraging, Uplifting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>If you think you are too small to make a diffe...</td>\n",
       "      <td>Dalai Lama</td>\n",
       "      <td>Inspirational, Funny, Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>God doesn't require us to succeed, he only req...</td>\n",
       "      <td>Mother Teresa</td>\n",
       "      <td>Success, God, Mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Change your thoughts and you change your world...</td>\n",
       "      <td>Norman Vincent Peale</td>\n",
       "      <td>Inspirational, Motivational, Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                QUOTE                AUTHOR  \\\n",
       "0   The essence of strategy is choosing what not t...        Michael Porter   \n",
       "1   One cannot and must not try to erase the past ...            Golda Meir   \n",
       "2   Patriotism means to stand by the country. It d...    Theodore Roosevelt   \n",
       "3   Death is something inevitable. When a man has ...        Nelson Mandela   \n",
       "4   You have to love a nation that celebrates its ...          Erma Bombeck   \n",
       "..                                                ...                   ...   \n",
       "95  When the going gets weird, the weird turn pro....    Hunter S. Thompson   \n",
       "96  When a train goes through a tunnel and it gets...       Corrie Ten Boom   \n",
       "97  If you think you are too small to make a diffe...            Dalai Lama   \n",
       "98  God doesn't require us to succeed, he only req...         Mother Teresa   \n",
       "99  Change your thoughts and you change your world...  Norman Vincent Peale   \n",
       "\n",
       "                               TYPE OF QUOTE  \n",
       "0   Essence, Deep Thought, Transcendentalism  \n",
       "1                  Inspiration, Past, Trying  \n",
       "2                        Country, Peace, War  \n",
       "3         Inspirational, Motivational, Death  \n",
       "4               4th Of July, Food, Patriotic  \n",
       "..                                       ...  \n",
       "95                    Music, Sports, Hunting  \n",
       "96             Trust, Encouraging, Uplifting  \n",
       "97              Inspirational, Funny, Change  \n",
       "98                      Success, God, Mother  \n",
       "99       Inspirational, Motivational, Change  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making dataframe of quotes from first page\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'QUOTE':quote,'AUTHOR':author,'TYPE OF QUOTE':type_quote})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bb678dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes=[]\n",
    "authors=[]\n",
    "types=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cf4a0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapting data from the next pages\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    qut=driver.find_elements(By.CLASS_NAME,'wrap-block')\n",
    "    for i in qut:\n",
    "        quotes.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]/a')(# to scrap from the next pages as well)\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "85da2a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f4473469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapting data from the next pages\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    summs=driver.find_elements(By.CLASS_NAME,'author')\n",
    "    for i in summs:\n",
    "        authors.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]/a')(# to scrap from the next pages as well)\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6165e2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "051d4325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapting data from the next pages\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    revs=driver.find_elements(By.CLASS_NAME,'tags')\n",
    "    for i in revs:\n",
    "        types.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]/a')(# to scrap from the next pages as well)\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f18e2def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2a6db613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUOTE</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>TYPE OF QUOTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Amelia Earhart</td>\n",
       "      <td>Inspirational, Life, Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Ludwig von Mises</td>\n",
       "      <td>Peace, War, Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Elizabeth Cady Stanton</td>\n",
       "      <td>Life, Strength, Courage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Benjamin Spock</td>\n",
       "      <td>Positive, Family, Trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Michael Jordan</td>\n",
       "      <td>Inspirational, Life, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 QUOTE  \\\n",
       "0    The essence of strategy is choosing what not t...   \n",
       "1    One cannot and must not try to erase the past ...   \n",
       "2    Patriotism means to stand by the country. It d...   \n",
       "3    Death is something inevitable. When a man has ...   \n",
       "4    You have to love a nation that celebrates its ...   \n",
       "..                                                 ...   \n",
       "995  Regret for the things we did can be tempered b...   \n",
       "996  America... just a nation of two hundred millio...   \n",
       "997  For every disciplined effort there is a multip...   \n",
       "998  The spiritual journey is individual, highly pe...   \n",
       "999  The mind is not a vessel to be filled but a fi...   \n",
       "\n",
       "                     AUTHOR                          TYPE OF QUOTE  \n",
       "0            Amelia Earhart           Inspirational, Life, Success  \n",
       "1          Ludwig von Mises                 Peace, War, Government  \n",
       "2    Elizabeth Cady Stanton                Life, Strength, Courage  \n",
       "3            Benjamin Spock                Positive, Family, Trust  \n",
       "4            Michael Jordan      Inspirational, Life, Motivational  \n",
       "..                      ...                                    ...  \n",
       "995        Sydney J. Harris      Love, Inspirational, Motivational  \n",
       "996      Hunter S. Thompson                 Gun, Two, Qualms About  \n",
       "997                Jim Rohn  Inspirational, Greatness, Best Effort  \n",
       "998                Ram Dass                 Spiritual, Truth, Yoga  \n",
       "999                Plutarch   Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making dataframe of top 100 quotes with their authors and type of quotes\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'QUOTE':quotes,'AUTHOR':authors,'TYPE OF QUOTE':types})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8d597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc3971a9",
   "metadata": {},
   "source": [
    "Q7: Write a python program to display list of respected former Prime Ministers of India (i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/general-knowledge/list-of-all-prime-ministers-of-india-1473165149-1\n",
    "scrap the mentioned data and make the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "430ce2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening given link of  page on automated chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(' https://www.jagranjosh.com/general-knowledge/list-of-all-prime-ministers-of-india-1473165149-1 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "47d5cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the table data\n",
    "table = driver.find_element(By.XPATH,'/html/body/div[1]/main/div[1]/div[1]/article/div[4]/div[6]/div')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fde9ad",
   "metadata": {},
   "source": [
    "Q8: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive cars in the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bed34ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening motor1 page on automated chrome browser\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('   https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e063e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering 50 most expensive cars in search\n",
    "designation = driver.find_element(By.ID,\"search_input\")\n",
    "designation.send_keys('50 most expensive cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2a409d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH, \"/html/body/div[9]/div[2]/div/div/div[3]/div/div/div/form/button[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "17033931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on link \n",
    "title_link=driver.find_element(By.XPATH, \"/html/body/div[9]/div[9]/div/div[1]/div/div/div[1]/div/div[1]/h3/a\")\n",
    "title_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fc498a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_name=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "62bc08d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping expensive car names as desired\n",
    "car_tags=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in car_tags:\n",
    "    rat=i.text\n",
    "    car_name.append(rat)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9d021046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 0\n"
     ]
    }
   ],
   "source": [
    "print(len(car_name),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "302e2c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>McLaren Senna GTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Czinger 21C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lotus Evija</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Delage D12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ferrari Daytona SP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Hennessey Venom F5 Revolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Zenvo Aurora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Aspark Owl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>McLaren Solus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Pagani Huayra Evo R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Gordon Murray Automotive T.50s Niki Lauda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pininfarina B95 Speedster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Chiron Profilée</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rolls-Royce Boat Tail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce La Rose Noire Droptail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Most Expensive Cars In The World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        TITLE\n",
       "0                           McLaren Senna GTR\n",
       "1                                 Czinger 21C\n",
       "2                               Ferrari Monza\n",
       "3                          Gordon Murray T.33\n",
       "4                           Koenigsegg Gemera\n",
       "5                          Hennessey Venom F5\n",
       "6                             Bentley Bacalar\n",
       "7               Hispano Suiza Carmen Boulogne\n",
       "8                      Bentley Mulliner Batur\n",
       "9                                 SSC Tuatara\n",
       "10                                Lotus Evija\n",
       "11                        Aston Martin Vulcan\n",
       "12                                 Delage D12\n",
       "13                        Ferrari Daytona SP3\n",
       "14                          McLaren Speedtail\n",
       "15                               Rimac Nevera\n",
       "16                              Pagani Utopia\n",
       "17                       Pininfarina Battista\n",
       "18                         Gordon Murray T.50\n",
       "19                       Lamborghini Countach\n",
       "20              Hennessey Venom F5 Revolution\n",
       "21                   Mercedes-AMG Project One\n",
       "22                               Zenvo Aurora\n",
       "23                        Aston Martin Victor\n",
       "24                Hennessey Venom F5 Roadster\n",
       "25                           Koenigsegg Jesko\n",
       "26                                 Aspark Owl\n",
       "27                      Aston Martin Valkyrie\n",
       "28                  W Motors Lykan Hypersport\n",
       "29                              McLaren Solus\n",
       "30                        Pagani Huayra Evo R\n",
       "31                           Lamborghini Sian\n",
       "32                           Koenigsegg CC850\n",
       "33            Bugatti Chiron Super Sport 300+\n",
       "34  Gordon Murray Automotive T.50s Niki Lauda\n",
       "35                  Pagani Huayra Roadster BC\n",
       "36                         Lamborghini Veneno\n",
       "37                             Bugatti Bolide\n",
       "38                  Pininfarina B95 Speedster\n",
       "39                            Bugatti Mistral\n",
       "40                               Bugatti Divo\n",
       "41                        Pagani Huayra Imola\n",
       "42                           Pagani Codalunga\n",
       "43                   Mercedes-Maybach Exelero\n",
       "44                         Bugatti Centodieci\n",
       "45                    Bugatti Chiron Profilée\n",
       "46                       Rolls-Royce Sweptail\n",
       "47                   Bugatti La Voiture Noire\n",
       "48                      Rolls-Royce Boat Tail\n",
       "49         Rolls-Royce La Rose Noire Droptail\n",
       "50           Most Expensive Cars In The World"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'TITLE':car_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca3ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1abcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dce2627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3795d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
